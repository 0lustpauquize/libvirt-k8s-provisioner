--- 
- name: Prepare cluster to install rook
  hosts: vm_host
  run_once: true
  vars_files:
    - vars/k8s_cluster.yml
  tasks:
    - name: Take all required steps to install Rook in your cluster
      block:
        - name: Ensure the needed Namespaces exist.
          kubernetes.core.k8s:
            definition:
              api_version: v1
              kind: Namespace
              metadata:
                name: rook-ceph
            kubeconfig: "{{ workspace_directory.base_path }}/clusters/{{ k8s.cluster_name }}/admin.kubeconfig"
            state: present

        - name: Add helm chart repository for Rook
          kubernetes.core.helm_repository:
            name: "{{ item.name }}"
            repo_url: "{{ item.repo_url }}"
          loop:
            - name: "{{ rook.operator.chart.name }}"
              repo_url: "{{ rook.operator.chart.url }}"
            - name: "{{ rook.cluster.chart.name }}"
              repo_url: "{{ rook.cluster.chart.url }}"

        - name: Ensure rook-operator helm chart is installed
          kubernetes.core.helm:
            name: rook-operator
            chart_ref: "{{ rook.operator.chart.ref }}"
            kubeconfig: "{{ workspace_directory.base_path }}/clusters/{{ k8s.cluster_name }}/admin.kubeconfig"
            release_namespace: rook-ceph
            update_repo_cache: true
            values:
              csi:
                provisionerReplicas: "{{ rook_ceph.rook_cluster_size }}"
            wait: true

        - name: Trigger rook template
          ansible.builtin.template:
            src: templates/rook-values.yml.j2
            dest: /tmp/{{ k8s.cluster_name }}/rook-values.yaml

        - name: Ensure rook-ceph-cluster helm chart is installed
          kubernetes.core.helm:
            name: rook-ceph-cluster
            chart_ref: "{{ rook.cluster.chart.ref }}"
            kubeconfig: "{{ workspace_directory.base_path }}/clusters/{{ k8s.cluster_name }}/admin.kubeconfig"
            release_namespace: rook-ceph
            update_repo_cache: true
            values:
              cephClusterSpec:
                cephVersion:
                  image: quay.io/ceph/ceph:v17.2.1
                  allowUnsupported: false
                mon:
                  count: "{{ rook_ceph.rook_cluster_size | int }}"
                  allowMultiplePerNode: false

                mgr:
                  count: "{{ rook_ceph.rook_cluster_size | int }}"
                  allowMultiplePerNode: false
              configOverride: |
                [global]
                mon_warn_on_pool_no_redundancy = false
                bdev_flock_retry = 20
                bluefs_buffered_io = false
                mon_allow_pool_delete = true
                osd_pool_default_size = "{{ rook_ceph.rook_cluster_size | int }}"
                osd_pool_default_min_size = "{{ rook_ceph.rook_cluster_size | int }}"
              cephBlockPools:
                - name: ceph-blockpool
                  spec:
                    failureDomain: host
                    replicated:
                      size: "{{ rook_ceph.rook_cluster_size | int }}"
                  storageClass:
                    enabled: true
                    name: ceph-block
                    isDefault: true
                    reclaimPolicy: Delete
                    allowVolumeExpansion: true
              cephFileSystems:
                - name: ceph-filesystem
                  spec:
                    metadataPool:
                      replicated:
                        size: "{{ rook_ceph.rook_cluster_size | int }}"
                    dataPools:
                      - failureDomain: host
                        replicated:
                          size: "{{ rook_ceph.rook_cluster_size | int }}"
                        name: data0
                    metadataServer:
                      activeCount: "{{ rook_ceph.rook_cluster_size | int }}"
                      activeStandby: false
                      resources:
                        limits:
                          cpu: "2000m"
                          memory: "4Gi"
                        requests:
                          cpu: "1000m"
                          memory: "512Mi"
                      priorityClassName: system-cluster-critical
                  storageClass:
                    enabled: true
                    isDefault: false
                    name: ceph-filesystem
                    pool: data0
                    reclaimPolicy: Delete
              cephObjectStores:
                - name: ceph-objectstore
                  spec:
                    metadataPool:
                      failureDomain: host
                      replicated:
                        size: "{{ rook_ceph.rook_cluster_size | int }}"
                    dataPool:
                      failureDomain: host
                      erasureCoded:
                        dataChunks: 2
                        codingChunks: 1
                    preservePoolsOnDelete: true
                    gateway:
                      port: 80
                      resources:
                        limits:
                          cpu: "2000m"
                          memory: "2Gi"
                        requests:
                          cpu: "1000m"
                          memory: "1Gi"
                      instances: 1
                      priorityClassName: system-cluster-critical
                    healthCheck:
                      bucket:
                        interval: 60s
                  storageClass:
                    enabled: true
                    name: ceph-bucket
                    reclaimPolicy: Delete
            wait: true
      when: rook_ceph.install_rook
